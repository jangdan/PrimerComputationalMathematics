---
interact_link: notebooks/maths/taylor-series.ipynb
kernel_name: python3
kernel_path: notebooks/maths
has_widgets: false
title: |-
  taylor-series
pagenum: 2
prev_page:
  url: /maths/intro.html
next_page:
  url: /coding/intro.html
suffix: .ipynb
search: x y f t h delta point frac function approximation o terms series e mathcal yn c case n small error taylor example where its us value wikipedia our limit solution constant very term above method consider org expansion linear slope line size ldots notation right text dot step approximate well en wiki derivative form black errors order rightarrow left problem second next tn single computational variable better called lets plot assuming assume using following rhs infinite iv larger behaviour sufficiently le enough dependent considering quad numerical quadratically algorithm euler simple exact arbitrary derivatives things suppose really only cant approx

comment: "***PROGRAMMATICALLY GENERATED, DO NOT EDIT. SEE ORIGINAL FILES IN /notebooks***"
---

    <main class="jupyter-page">
    <div id="page-info"><div id="page-title">taylor-series</div>
</div>
    
<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Taylor-series">Taylor series<a class="anchor-link" href="#Taylor-series"> </a></h1><p>Hopefully most of you will have seen Taylor series before.</p>
<p>A Taylor series is a method by which we can approximate an arbitrary function by a sum of terms made up of that function and its derivatives at a single point.</p>
<p>This concept underlies many things (especially in computational science) so it's worth us spending some time reviewing it.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Motivation---a-constant-approximation">Motivation - a constant approximation<a class="anchor-link" href="#Motivation---a-constant-approximation"> </a></h2><p>Consider a function of a single independent variable:  $f(x)$</p>
<p>Suppose this function is really really expensive to evaluate. Suppose I have already evaluated it at a single $x$ value, call it $x_0$, i.e. I know the value of $f(x_0)$.</p>
<p>Given only this information, what is the best guess (estimation/approximation) I can make for $f(x)$ for a choice $x\ne x_0$?</p>
<p>Well I can't really do anything better than</p>
$$  f(x) \approx f(x_0)$$<p>This may seem a hopeless approximation, but it can be used in some situations. Pretend $f$ is a weather forecast and $x$ is time. This just says that for a forecast of the weather tomorrow use what we see today - this is a real technique called <a href="https://en.wikipedia.org/wiki/Weather_forecasting#Persistence"><em>persistent forecast</em></a> ("today equals tomorrow").</p>
<p>"... This makes persistence a 'hard to beat' method for forecasting longer time periods": <a href="http://ww2010.atmos.uiuc.edu/(Gh)/guides/mtr/fcst/mth/prst.rxml">http://ww2010.atmos.uiuc.edu/(Gh)/guides/mtr/fcst/mth/prst.rxml</a></p>
<p>Let's consider an example:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>and plot our current situation, assuming that $x_0=0$. We call this the expansion point - we are constructing an approximation "around this point".</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="n">ax1</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>

<span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;A constant approximation&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;$x$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>

<span class="c1"># define our x for plotting purposes</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>

<span class="c1"># plot exact function</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Exact function&#39;</span><span class="p">)</span>

<span class="c1"># define our approximation</span>
<span class="n">x0</span> <span class="o">=</span> <span class="mf">0.0</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">f</span><span class="p">(</span><span class="n">x0</span><span class="p">),</span> <span class="s1">&#39;ro&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Expansion point&#39;</span><span class="p">)</span>

<span class="c1"># and plot the constant approximation</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Constant approximation&#39;</span><span class="p">)</span>

<span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.legend.Legend at 0x209f17c4c08&gt;</pre>
</div>

</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../images/maths/taylor-series_5_1.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Can I have any confidence in this guess?</p>
<ol>
<li>Yes if it turns out that the function $f$ is actually a constant.</li>
</ol>
<ol>
<li>Yes, if I can assume that $f$ doesn't vary very much in the vicinity of $x_0$, and if we are interested in $x$ values that are close to $x_0$.</li>
</ol>
<p>How can I do better?</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Motivation---a-linear-approximation-(a-&quot;linearisation&quot;)">Motivation - a linear approximation (a "linearisation")<a class="anchor-link" href="#Motivation---a-linear-approximation-(a-&quot;linearisation&quot;)"> </a></h2><p>The obvious improvement we can make is to approximate the true function with a linear approximation rather than a constant.</p>
<p>This is a common way to write a linear function:</p>
$$ y = mx + c$$<p>where $m$ is the slope and $c$ is the intercept - the $y$ value the line hits the $x=0$ axis at.</p>
<p>We consider an approximation, or an expansion, (or in this case a "linearisation") "about a point".</p>
<p>For us the point is $x_0$ and it makes sense for us to make the slope of the linear approximation the same as the derivative of the function at this point.</p>
<p>So we are now using the value of $f$ at $x_0$ AND the value of the derivative of $f$ at $x_0$:  $m = f'(x_0)$.</p>
<p>This is the formula for the linear line with this slope:</p>
$$ y = f'(x_0) x + c$$<p>where choice of $c$ moves the linear line up and down. We want it to pass through the function at $x_0$ as well of course, and this allows us to figure out what value $c$ should take.</p>
<p>Actually we generally write the linearisation in the following form</p>
$$ f(x) \approx f(x_0) + (x-x_0)f'(x_0)$$<p>so when $(x-x_0)$ is zero, we are at the expansion point and we indeed get $f(x_0)$ on the RHS. As we move away from that point $(x-x_0)$ grows and our approximation adds a correction based on the size of the derivative at $x_0$.</p>
<p>Let's plot this. First we need to define the derivative:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># of course for our example f this is trivial:</span>
<span class="k">def</span> <span class="nf">fx</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="n">ax1</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>

<span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;A constant approximation&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;$x$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>

<span class="c1"># define our x for plotting purposes</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>

<span class="c1"># plot exact function</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Exact function&#39;</span><span class="p">)</span>

<span class="c1"># define our approximation</span>
<span class="n">x0</span> <span class="o">=</span> <span class="mf">0.0</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">x0</span><span class="p">)</span><span class="o">*</span><span class="n">fx</span><span class="p">(</span><span class="n">x0</span><span class="p">))</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">f</span><span class="p">(</span><span class="n">x0</span><span class="p">),</span> <span class="s1">&#39;ro&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Expansion point&#39;</span><span class="p">)</span>

<span class="c1"># and plot the constant approximation</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Linear approximation&#39;</span><span class="p">)</span>

<span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.legend.Legend at 0x209f1900dc8&gt;</pre>
</div>

</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../images/maths/taylor-series_9_1.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This is clearly an improved approximation compared to the constant one.</p>
<p>However the same accuracy points hold: if we are a long way from the expansion point, or if $f$ is very complex, this may not be a good approximation.</p>
<p>Can we do better - yes we can consider the curvature of the black line in addition to its value and its slope, i.e. we can include a term proportional to $f''(x_0)$ to our approximation.</p>
<p>and so on...</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This is the formula for the infinite Taylor series <em>about (or around) the point $x_0$</em></p>
$$f(x) = f(x_0) + (x - x_0) f'(x_0) + \frac{(x - x_0)^2}{2!} f''(x_0) + \frac{(x - x_0)^3}{3!} f'''(x_0) +
\frac{(x - x_0)^4}{4!} f^{(iv)}(x_0) + \ldots$$<p>An equivalent way of writing this expansion is</p>
$$ f(x_0+h)  = f(x_0) + hf'(x_0) + \frac{h^2}{2!}f''(x_0) + \frac{h^3}{3!}f'''(x_0) + \ldots $$<p>or replace $h$ by the notation $\Delta x$ or $\delta x$.</p>
<p>As we include more and more terms our approximation improves - see the following animated gif from Wikipedia which explains the point.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Taylor-series-example">Taylor series example<a class="anchor-link" href="#Taylor-series-example"> </a></h4><p><em>Wikipedia image: The exponential function (in blue), and the sum of the first (n + 1) terms of its Taylor series expansion around the point 0 (in red).</em></p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/6/62/Exp_series.gif" width=200x></p>
<p>More terms equate with a better approximation valid a larger distance from $x_0$.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Aside:-Big-O-notation">Aside: Big O notation<a class="anchor-link" href="#Aside:-Big-O-notation"> </a></h3><p>When talking about terms in infinite series (terms we will often be forces to truncate, i.e. throw away), or talking about errors, convergence, complexity, run times etc, so-called <a href="https://en.wikipedia.org/wiki/Big_O_notation">Big-O</a> is very useful.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As an alternative to writing "$ \ldots $" in the above infinite expansions, we can also write</p>
$$f(x) = f(x_0) + (x - x_0) f'(x_0) + \frac{(x - x_0)^2}{2!} f''(x_0) + \frac{(x - x_0)^3}{3!} f'''(x_0) + \mathcal{O}((x - x_0)^4)$$<p>or</p>
$$ f(x_0+h) = f(x_0) + hf'(x_0) + \frac{h^2}{2!}f''(x_0) + \frac{h^3}{3!}f'''(x_0) + \mathcal{O}(h^4) $$<p>What does this mean?</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="In-Mathematics">In Mathematics<a class="anchor-link" href="#In-Mathematics"> </a></h4><p>Well simply $\mathcal{O}$ here means "order".</p>
<p>More formally it is used to signify (place bounds on) the limiting behaviour of the magnitude of a mathematical term (or an algorithm's runtime).</p>
<p>So based on the the example above we have simply replaced the terms</p>
$$ \frac{h^4}{4!} f^{(iv)}(x_0) +  \frac{h^5}{5!} f^{(v)}(x_0) + \ldots $$<p>with</p>
$$ \mathcal{O}(h^4) $$<p>"in the limit" (and implicitly for this use application we are interested in the limit as $h\rightarrow 0$)</p>
<p>i.e. we have written that</p>
$$ \frac{h^4}{4!} f^{(iv)}(x_0) +  \frac{h^5}{5!} f^{(v)}(x_0) + \ldots  =  \mathcal{O}(h^4) $$<p>this is stating that as $h$ tends to zero the LHS can bounded in magnitude by a term of the form</p>
$$ C h^4 $$<p>where $C$ is a constant, i.e. there exists a constant $C$ such that for all sufficiently small $h$</p>
$$\left| \frac{h^4}{4!} f^{(iv)}(x_0) +  \frac{h^5}{5!} f^{(v)}(x_0) + \ldots \right| \le C h^4 $$<p>In our case the point is that, assuming $f$ is a well-behaved function, i.e. it's derivatives are bounded, then there will be a small enough $h$ such that the terms dependent on the 5th and higher powers or $h$ are very small relative to the first term</p>
<p>They can't be ignored, but we can select a $C$ which is a bit larger than original factor ${h^4}/{4!}$ so that the above holds.</p>
<p>The point here isn't to actually find $C$, this is just notation to help convey a point.</p>
<p>It's important when analysing errors in algorithms.</p>
<p>Note that for this case we were considering the limit of small $h$ and so the lowest power eventually becomes dominant, the opposite situation would occur if we were considering the limit of large $h$.</p>
<p>With errors we are generally thinking about the former case, with run-times (where $h$ might be replaced with some measure of the size of the problem) we are in the latter case.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Example">Example<a class="anchor-link" href="#Example"> </a></h4><p>Consider</p>
$$g(y) = 3y^2 - y^3 + 9y^4$$<p>in the limit as $y\rightarrow 0$.</p>
<p>We can show that</p>
$$\left| 3y^2 - y^3 + 9y^4 \right| \le \left| 3y^2\right| + \left|y^3\right| + \left|9y^4 \right| \le 3y^2 + y^2 + 9y^2 \le 13 y^2$$<p>as we are considering the case as $y$ gets small. Hence we can write</p>
$$g(y) = 3y^2 - y^3 + 9y^4 = \mathcal{O}(y^2) \quad\text{as}\quad y\rightarrow 0$$<p>If we were considering the case of $y\rightarrow \infty$, then we would write instead</p>
$$g(y) = \mathcal{O}(y^4) \quad\text{as}\quad y\rightarrow \infty$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>When dealing with numerical errors you may see things like</p>
$$\text{error} \approx 10^{-5}\Delta t +  10^{5}\Delta t^2$$<p>For larger values of $\Delta t$ the second term will clearly dominate due to the relative size of the constant in front of it compared to the first term.</p>
<p>But when performing a convergence analysis, i.e. investigating how the error drops as $\Delta t$ is reduced, there will come a point for small enough $\Delta t$ that the first term starts to dominate, and from the point onwards the error will decay linearly rather than quadratically, i.e. halving $\Delta t$ leads to a reduction in the error by a factor of 2 rather than 4.</p>
<p>So we would say that</p>
$$\text{error} = \mathcal{O}(\Delta t)$$<p>even though at larger $\Delta t$ values the error would be observed to decay quadratically as we reduce $\Delta t$.</p>
<p>We use the expression "in the asymptotic limit" to refer to region of parameter space where the leading order behaviour dominates. For the above example if we observe something that looks like second order behaviour (when we expect first) we would explain this away by saying that we are not in the asymptotic limit. If we see very close to first order behaviour then we would say we are in the asymptotic limit.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="In-Computer/Computational-Science">In Computer/Computational Science<a class="anchor-link" href="#In-Computer/Computational-Science"> </a></h4><p>For the cost of algorithms we use the notation in a similar manner.</p>
<p>An algorithm is said to have (<em>time</em> or <em>algorithmic</em> or <em>computational</em>) <a href="https://en.wikipedia.org/wiki/Time_complexity">complexity</a> of $\mathcal{O}(n^2)$ for example,
if for large enough $n$, where $n$ is a measure of the problem size, the computational cost grows quadratically - for every doubling of the problem size the cost grows by a factor 4.</p>
<p>When it comes to complexity it's quite common to see things like $\mathcal{O}(n \log n)$, i.e. the algorithm scales worse than linearly, but not as bad as quadratically.</p>
<p>For some examples see <a href="https://en.wikipedia.org/wiki/Computational_complexity_of_mathematical_operations">https://en.wikipedia.org/wiki/Computational_complexity_of_mathematical_operations</a></p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Truncation-error">Truncation error<a class="anchor-link" href="#Truncation-error"> </a></h2><p>In principle we can use Taylor series to approximate a (sufficiently smooth) function with arbitrary accuracy as long as we use sufficiently many terms, but in practice we will have to truncate.</p>
<p>In the next section we will use similar ideas to compute an approximate solution to a differential equations, we will do this by approximating the operation of taking a derivative.</p>
<p>Again by making use of enough terms from a Taylor series we can construct approximations of derivatives with arbitrary accuracy, but again in practice we will have to truncate.</p>
<p>In both cases the act of limiting the number of terms we use introduces an error.</p>
<p>Since we are truncating an infinite series at some point, this type of error is often called a <a href="https://en.wikipedia.org/wiki/Truncation_error"><em>truncation error</em></a>.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Using-Taylor-series-to-solve-an-ODE-numerically">Using Taylor series to solve an ODE numerically<a class="anchor-link" href="#Using-Taylor-series-to-solve-an-ODE-numerically"> </a></h1>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Deriving-the-forward-Euler-scheme">Deriving the forward Euler scheme<a class="anchor-link" href="#Deriving-the-forward-Euler-scheme"> </a></h2><p>Let's suppose we have an ODE of the form</p>
$$y' = f(t,y) \qquad\left[\text{NB. on the LHS we could also use the notation $\dot{y}$ or $\frac{dy}{dt}$}\right]
$$<p>This is describing a solution function of the form $y\equiv y(t)$, i.e. the solution $y$ is a function of one variable - $t$.</p>
<p>$y$ is called the <em>dependent variable</em> and $t$ the <em>dependent variable</em>.</p>
<p>[NB. in the case where $y$ is multi-dimensional - a vector of unknowns/dependent variables - we would talk about a <em>system of ODEs</em>. For the case where there are more than one independent variables then we need to start thinking about <em>partial differential equations (PDEs)</em>, covered later in this module and in ACSE-3].</p>
<p>For example</p>
$$y' = \exp(t), \qquad\text{or equivalently} \qquad y' = y$$<p>the first is an example where the RHS is a function of $t$ only, the second a function of $y$ only.</p>
<p>This is an example where both $t$ and $y$ appear on the RHS:</p>
$$y' = y + t^3$$<p>The first two ($y'=y$ or $y'=\exp(t)$) are relatively easy for us to solve analytically, the final case is a bit more challenging and we may need to resort to a numerical approach (or attempt symbolic computation).</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can formulate a simple numerical solver using a truncated Taylor series.</p>
<p>From above we know that (assuming smoothness of the solution) the following is true:</p>
$$ y(t+\Delta t) = y(t) + \Delta t \, y'(t) + \frac{\Delta t^2}{2!}y''(t) + \frac{\Delta t^3}{3!}y'''(t) + \mathcal{O}(\Delta t^4),$$<p>Using the notation $y_n=y(t_n), \; y'_n=y'(t_n)$ etc, and assuming a uniform time step size $\Delta t$, this is equivalent to</p>
$$ y_{n+1} = y_n + \Delta t\, y'_n + \frac{\Delta t^2}{2!}y''_n + \frac{\Delta t^3}{3!}y'''_n + \mathcal{O}(\Delta t^4).$$<p>Dropping second-order terms (which we can justify if $y$ is "smooth", which means that $y''$ is "well-behaved", and $\Delta t$ is chosen to be sufficiently small so that the terms containing higher powers of $\Delta t$ are relatively speaking <em>very small</em>),</p>
<p>and noting that $y'_n = f(t_n,y_n)$ we are left with the discrete relation</p>
$$y_{n+1} = y_n + \Delta t \, f(t_n,y_n).$$<p><br></p>
<p>This is a very famous ODE solver, or time-stepping method - termed the <strong>forward Euler</strong> or <strong>explicit Euler</strong> method.</p>
<p>We have turned the continuous problem into a discrete one - we have discretised. And note that this is in a form similar to our logistic map, so we know that we can write a simple piece of code that iterates over $n$ to evaluate/predict/approximate the dynamics.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's consider the simple model problem</p>
$$y' = y$$<p>with the initial condition</p>
$$y(0)=1$$<p>and see what one step of the forward Euler method does, we will assume that we start at some $t$ from the exact solution at that time, i.e. the starting point indicated by the red dot in the following image is on the exact solution (black) line.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">ax1</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;One step of Forward Euler&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;$t$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;$y(t)$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>

<span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>

<span class="c1"># the RHS of the ODE</span>
<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">t</span><span class="p">,</span><span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">y</span>

<span class="c1"># an example solution trajectory (or solution to ODE $\dot{y}=f(y), y(0)=1$)</span>
<span class="k">def</span> <span class="nf">y</span><span class="p">(</span><span class="n">t</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>

<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">y</span><span class="p">(</span><span class="n">t</span><span class="p">),</span> <span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Trajectory $y=y(t)$&#39;</span><span class="p">)</span>

<span class="c1"># this is just some location in time</span>
<span class="n">t0</span> <span class="o">=</span> <span class="mf">0.35</span>
<span class="c1"># and an example of a time step size large enough we can see what the method is doing</span>
<span class="n">dt</span> <span class="o">=</span> <span class="mf">0.4</span>

<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">t0</span><span class="p">],</span> <span class="p">[</span><span class="n">y</span><span class="p">(</span><span class="n">t0</span><span class="p">)],</span> <span class="s1">&#39;ro&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">t0</span><span class="p">,</span> <span class="n">t0</span> <span class="o">+</span> <span class="n">dt</span><span class="p">],</span> <span class="p">[</span><span class="n">y</span><span class="p">(</span><span class="n">t0</span><span class="p">),</span> <span class="n">y</span><span class="p">(</span><span class="n">t0</span><span class="p">)</span> <span class="o">+</span> <span class="n">dt</span> <span class="o">*</span> <span class="n">f</span><span class="p">(</span><span class="n">t0</span><span class="p">,</span> <span class="n">y</span><span class="p">(</span><span class="n">t0</span><span class="p">))],</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;$y&#39;=f(t_0,y_0)$&quot;</span><span class="p">)</span>

<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">t0</span> <span class="o">+</span> <span class="n">dt</span><span class="p">],</span> <span class="p">[</span><span class="n">y</span><span class="p">(</span><span class="n">t0</span> <span class="o">+</span> <span class="n">dt</span><span class="p">)],</span> <span class="s1">&#39;ko&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Exact soln at $t_0 + \Delta t$&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">t0</span> <span class="o">+</span> <span class="n">dt</span><span class="p">],</span> <span class="p">[</span><span class="n">y</span><span class="p">(</span><span class="n">t0</span><span class="p">)</span> <span class="o">+</span> <span class="n">dt</span> <span class="o">*</span> <span class="n">f</span><span class="p">(</span><span class="n">t0</span><span class="p">,</span> <span class="n">y</span><span class="p">(</span><span class="n">t0</span><span class="p">))],</span> <span class="s1">&#39;go&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;FE numerical soln at $t_0 + \Delta t$&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../images/maths/taylor-series_24_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The black dot in the figure above shows what the true/exact solution at the new $n$ level is, while the green dot shows what the numerical solver predicts it to be.</p>
<p>The difference between the two is the error that has been introduced in a single step of the method.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now in the next step of the algorithm we of course have to start from the green dot as we assume in practice we don't know the black line.</p>
<p>The next step computes</p>
$$y_{n+1} = y_n + \Delta t \, f(t_n,y_n),$$<p>but note that $f$ for this particular simple test case is simply $y$.</p>
<p>We assume that we don't know what the exact solution is at this time level, and hence we can't read off the correct $t$ from the $x$ axis in the above plot and compute $\exp(t)$ in the RHS of our update. If we could then this would let us use the correct new slope at this time, i.e. the slope at the black dot.</p>
<p>Instead we are forced to read off the $y$ axis - notice that in this example this gives us a $y$ value that is too small, and hence an $f$ that is too small. Therefore our next update will give us a second point that is even more too small!</p>
<p>The moral of the story here is that <strong>errors generally accumulate</strong>, as we can see if we plot this next step of the algorithm:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">ax1</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Two steps of Forward Euler&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;$t$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;$y(t)$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>

<span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>

<span class="c1"># the RHS of the ODE</span>
<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">t</span><span class="p">,</span><span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">y</span>

<span class="c1"># an example solution trajectory (or solution to ODE $\dot{y}=f(y), y(0)=1$)</span>
<span class="k">def</span> <span class="nf">y</span><span class="p">(</span><span class="n">t</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>


<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">y</span><span class="p">(</span><span class="n">t</span><span class="p">),</span> <span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Trajectory $y=y(t)$&#39;</span><span class="p">)</span>

<span class="c1"># this is just some location in time</span>
<span class="n">t0</span> <span class="o">=</span> <span class="mf">0.35</span>
<span class="c1"># and an example of a time step size large enough we can see what the method is doing</span>
<span class="n">dt</span> <span class="o">=</span> <span class="mf">0.4</span>


<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">t0</span><span class="p">],</span> <span class="p">[</span><span class="n">y</span><span class="p">(</span><span class="n">t0</span><span class="p">)],</span> <span class="s1">&#39;ro&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">t0</span><span class="p">,</span> <span class="n">t0</span> <span class="o">+</span> <span class="n">dt</span><span class="p">],</span> <span class="p">[</span><span class="n">y</span><span class="p">(</span><span class="n">t0</span><span class="p">),</span> <span class="n">y</span><span class="p">(</span><span class="n">t0</span><span class="p">)</span> <span class="o">+</span> <span class="n">dt</span> <span class="o">*</span> <span class="n">f</span><span class="p">(</span><span class="n">t0</span><span class="p">,</span> <span class="n">y</span><span class="p">(</span><span class="n">t0</span><span class="p">))],</span> <span class="s1">&#39;b&#39;</span><span class="p">)</span>
<span class="n">y1</span> <span class="o">=</span> <span class="n">y</span><span class="p">(</span><span class="n">t0</span><span class="p">)</span> <span class="o">+</span> <span class="n">dt</span> <span class="o">*</span> <span class="n">f</span><span class="p">(</span><span class="n">t0</span><span class="p">,</span> <span class="n">y</span><span class="p">(</span><span class="n">t0</span><span class="p">))</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">t0</span> <span class="o">+</span> <span class="n">dt</span><span class="p">,</span> <span class="n">t0</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="n">dt</span><span class="p">],</span> <span class="p">[</span><span class="n">y1</span><span class="p">,</span> <span class="n">y1</span> <span class="o">+</span> <span class="n">dt</span> <span class="o">*</span> <span class="n">f</span><span class="p">(</span><span class="n">t0</span><span class="o">+</span><span class="n">dt</span><span class="p">,</span> <span class="n">y1</span><span class="p">)],</span> <span class="s1">&#39;b&#39;</span><span class="p">)</span>

<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">t0</span> <span class="o">+</span> <span class="n">dt</span><span class="p">,</span> <span class="n">t0</span><span class="o">+</span><span class="mi">2</span><span class="o">*</span><span class="n">dt</span><span class="p">],</span> <span class="p">[</span><span class="n">y</span><span class="p">(</span><span class="n">t0</span> <span class="o">+</span> <span class="n">dt</span><span class="p">),</span> <span class="n">y</span><span class="p">(</span><span class="n">t0</span><span class="o">+</span><span class="mi">2</span><span class="o">*</span><span class="n">dt</span><span class="p">)],</span> <span class="s1">&#39;ko&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">t0</span> <span class="o">+</span> <span class="n">dt</span><span class="p">,</span> <span class="n">t0</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="n">dt</span><span class="p">],</span> <span class="p">[</span><span class="n">y</span><span class="p">(</span><span class="n">t0</span><span class="p">)</span> <span class="o">+</span> <span class="n">dt</span> <span class="o">*</span> <span class="n">f</span><span class="p">(</span><span class="n">t0</span><span class="p">,</span> <span class="n">y</span><span class="p">(</span><span class="n">t0</span><span class="p">)),</span> <span class="n">y1</span> <span class="o">+</span> <span class="n">dt</span> <span class="o">*</span> <span class="n">f</span><span class="p">(</span><span class="n">t0</span><span class="o">+</span><span class="n">dt</span><span class="p">,</span> <span class="n">y1</span><span class="p">)],</span> <span class="s1">&#39;go&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[&lt;matplotlib.lines.Line2D at 0x2689480eef0&gt;]</pre>
</div>

</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../images/maths/taylor-series_27_1.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

 


    </main>
    